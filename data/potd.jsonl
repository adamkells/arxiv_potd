{"title":"DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model","abstract":"Traffic forecasting is an important problem in the operation and optimisation\nof transportation systems. State-of-the-art solutions train machine learning\nmodels by minimising the mean forecasting errors on the training data. The\ntrained models often favour periodic events instead of aperiodic ones in their\nprediction results, as periodic events often prevail in the training data.\nWhile offering critical optimisation opportunities, aperiodic events such as\ntraffic incidents may be missed by the existing models. To address this issue,\nwe propose DualCast -- a model framework to enhance the learning capability of\ntraffic forecasting models, especially for aperiodic events. DualCast takes a\ndual-branch architecture, to disentangle traffic signals into two types, one\nreflecting intrinsic {spatial-temporal} patterns and the other reflecting\nexternal environment contexts including aperiodic events. We further propose a\ncross-time attention mechanism, to capture high-order spatial-temporal\nrelationships from both periodic and aperiodic patterns. DualCast is versatile.\nWe integrate it with recent traffic forecasting models, consistently reducing\ntheir forecasting errors by up to 9.6% on multiple real datasets.","authors":["Xinyu Su","Feng Liu","Yanchuan Chang","Egemen Tanin","Majid Sarvi","Jianzhong Qi"],"url":"http://arxiv.org/pdf/2411.18286v1","published":"2024-11-27"}
{"title":"DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model","abstract":"Traffic forecasting is an important problem in the operation and optimisation\nof transportation systems. State-of-the-art solutions train machine learning\nmodels by minimising the mean forecasting errors on the training data. The\ntrained models often favour periodic events instead of aperiodic ones in their\nprediction results, as periodic events often prevail in the training data.\nWhile offering critical optimisation opportunities, aperiodic events such as\ntraffic incidents may be missed by the existing models. To address this issue,\nwe propose DualCast -- a model framework to enhance the learning capability of\ntraffic forecasting models, especially for aperiodic events. DualCast takes a\ndual-branch architecture, to disentangle traffic signals into two types, one\nreflecting intrinsic {spatial-temporal} patterns and the other reflecting\nexternal environment contexts including aperiodic events. We further propose a\ncross-time attention mechanism, to capture high-order spatial-temporal\nrelationships from both periodic and aperiodic patterns. DualCast is versatile.\nWe integrate it with recent traffic forecasting models, consistently reducing\ntheir forecasting errors by up to 9.6% on multiple real datasets.","authors":["Xinyu Su","Feng Liu","Yanchuan Chang","Egemen Tanin","Majid Sarvi","Jianzhong Qi"],"url":"http://arxiv.org/pdf/2411.18286v1","published":"2024-11-27"}
{"title":"DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model","abstract":"Traffic forecasting is an important problem in the operation and optimisation\nof transportation systems. State-of-the-art solutions train machine learning\nmodels by minimising the mean forecasting errors on the training data. The\ntrained models often favour periodic events instead of aperiodic ones in their\nprediction results, as periodic events often prevail in the training data.\nWhile offering critical optimisation opportunities, aperiodic events such as\ntraffic incidents may be missed by the existing models. To address this issue,\nwe propose DualCast -- a model framework to enhance the learning capability of\ntraffic forecasting models, especially for aperiodic events. DualCast takes a\ndual-branch architecture, to disentangle traffic signals into two types, one\nreflecting intrinsic {spatial-temporal} patterns and the other reflecting\nexternal environment contexts including aperiodic events. We further propose a\ncross-time attention mechanism, to capture high-order spatial-temporal\nrelationships from both periodic and aperiodic patterns. DualCast is versatile.\nWe integrate it with recent traffic forecasting models, consistently reducing\ntheir forecasting errors by up to 9.6% on multiple real datasets.","authors":["Xinyu Su","Feng Liu","Yanchuan Chang","Egemen Tanin","Majid Sarvi","Jianzhong Qi"],"url":"http://arxiv.org/pdf/2411.18286v1","published":"2024-11-27"}
{"title":"DualCast: Disentangling Aperiodic Events from Traffic Series with a Dual-Branch Model","abstract":"Traffic forecasting is an important problem in the operation and optimisation\nof transportation systems. State-of-the-art solutions train machine learning\nmodels by minimising the mean forecasting errors on the training data. The\ntrained models often favour periodic events instead of aperiodic ones in their\nprediction results, as periodic events often prevail in the training data.\nWhile offering critical optimisation opportunities, aperiodic events such as\ntraffic incidents may be missed by the existing models. To address this issue,\nwe propose DualCast -- a model framework to enhance the learning capability of\ntraffic forecasting models, especially for aperiodic events. DualCast takes a\ndual-branch architecture, to disentangle traffic signals into two types, one\nreflecting intrinsic {spatial-temporal} patterns and the other reflecting\nexternal environment contexts including aperiodic events. We further propose a\ncross-time attention mechanism, to capture high-order spatial-temporal\nrelationships from both periodic and aperiodic patterns. DualCast is versatile.\nWe integrate it with recent traffic forecasting models, consistently reducing\ntheir forecasting errors by up to 9.6% on multiple real datasets.","authors":["Xinyu Su","Feng Liu","Yanchuan Chang","Egemen Tanin","Majid Sarvi","Jianzhong Qi"],"url":"http://arxiv.org/pdf/2411.18286v1","published":"2024-11-27"}
{"title":"Differentiable Causal Discovery For Latent Hierarchical Causal Models","abstract":"Discovering causal structures with latent variables from observational data\nis a fundamental challenge in causal discovery. Existing methods often rely on\nconstraint-based, iterative discrete searches, limiting their scalability to\nlarge numbers of variables. Moreover, these methods frequently assume linearity\nor invertibility, restricting their applicability to real-world scenarios. We\npresent new theoretical results on the identifiability of nonlinear latent\nhierarchical causal models, relaxing previous assumptions in literature about\nthe deterministic nature of latent variables and exogenous noise. Building on\nthese insights, we develop a novel differentiable causal discovery algorithm\nthat efficiently estimates the structure of such models. To the best of our\nknowledge, this is the first work to propose a differentiable causal discovery\nmethod for nonlinear latent hierarchical models. Our approach outperforms\nexisting methods in both accuracy and scalability. We demonstrate its practical\nutility by learning interpretable hierarchical latent structures from\nhigh-dimensional image data and demonstrate its effectiveness on downstream\ntasks.","authors":["Parjanya Prashant","Ignavier Ng","Kun Zhang","Biwei Huang"],"url":"http://arxiv.org/pdf/2411.19556v1","published":"2024-11-29"}
{"title":"Differentiable Causal Discovery For Latent Hierarchical Causal Models","abstract":"Discovering causal structures with latent variables from observational data\nis a fundamental challenge in causal discovery. Existing methods often rely on\nconstraint-based, iterative discrete searches, limiting their scalability to\nlarge numbers of variables. Moreover, these methods frequently assume linearity\nor invertibility, restricting their applicability to real-world scenarios. We\npresent new theoretical results on the identifiability of nonlinear latent\nhierarchical causal models, relaxing previous assumptions in literature about\nthe deterministic nature of latent variables and exogenous noise. Building on\nthese insights, we develop a novel differentiable causal discovery algorithm\nthat efficiently estimates the structure of such models. To the best of our\nknowledge, this is the first work to propose a differentiable causal discovery\nmethod for nonlinear latent hierarchical models. Our approach outperforms\nexisting methods in both accuracy and scalability. We demonstrate its practical\nutility by learning interpretable hierarchical latent structures from\nhigh-dimensional image data and demonstrate its effectiveness on downstream\ntasks.","authors":["Parjanya Prashant","Ignavier Ng","Kun Zhang","Biwei Huang"],"url":"http://arxiv.org/pdf/2411.19556v1","published":"2024-11-29"}
{"title":"LLMForecaster: Improving Seasonal Event Forecasts with Unstructured Textual Data","abstract":"Modern time-series forecasting models often fail to make full use of rich\nunstructured information about the time series themselves. This lack of proper\nconditioning can lead to obvious model failures; for example, models may be\nunaware of the details of a particular product, and hence fail to anticipate\nseasonal surges in customer demand in the lead up to major exogenous events\nlike holidays for clearly relevant products. To address this shortcoming, this\npaper introduces a novel forecast post-processor -- which we call LLMForecaster\n-- that fine-tunes large language models (LLMs) to incorporate unstructured\nsemantic and contextual information and historical data to improve the\nforecasts from an existing demand forecasting pipeline. In an industry-scale\nretail application, we demonstrate that our technique yields statistically\nsignificantly forecast improvements across several sets of products subject to\nholiday-driven demand surges.","authors":["Hanyu Zhang","Chuck Arvin","Dmitry Efimov","Michael W. Mahoney","Dominique Perrault-Joncas","Shankar Ramasubramanian","Andrew Gordon Wilson","Malcolm Wolff"],"url":"http://arxiv.org/pdf/2412.02525v1","published":"2024-12-03"}
{"title":"Modeling and Discovering Direct Causes for Predictive Models","abstract":"We introduce a causal modeling framework that captures the input-output\nbehavior of predictive models (e.g., machine learning models) by representing\nit using causal graphs. The framework enables us to define and identify\nfeatures that directly cause the predictions, which has broad implications for\ndata collection and model evaluation. We show two assumptions under which the\ndirect causes can be discovered from data, one of which further simplifies the\ndiscovery process. In addition to providing sound and complete algorithms, we\npropose an optimization technique based on an independence rule that can be\nintegrated with the algorithms to speed up the discovery process both\ntheoretically and empirically.","authors":["Yizuo Chen","Amit Bhatia"],"url":"http://arxiv.org/pdf/2412.02878v1","published":"2024-12-03"}
